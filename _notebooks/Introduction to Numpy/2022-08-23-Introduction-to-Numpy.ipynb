{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to NumPy\n",
    "\n",
    "\n",
    "> NumPy is an essential Python library. TensorFlow and scikit-learn use NumPy arrays as inputs, and pandas and Matplotlib are built on top of NumPy. In this Introduction to NumPy course, you'll become a master wrangler of NumPy's core object - arrays! \n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Hai Nguyen\n",
    "- categories: [Datacamp, Python, NumPy, Tree Census, Monet array, Array Transformations, Array Mathematics]\n",
    "- image: images/numpy_intro.png\n",
    "- hide: false\n",
    "- search_exclude: true\n",
    "- metadata_key1: metadata_value1\n",
    "- metadata_key2: metadata_value2 \n",
    "- use_plotly: true\n",
    "\n",
    "> Using data from New York City's tree census, you'll create, sort, filter, and update arrays. You'll discover why NumPy is so efficient and use broadcasting and vectorization to make your NumPy code even faster. By the end of the course, you'll be using 3D arrays to alter a Claude Monet painting, and you'll understand why such array alterations are essential tools for machine learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "monthly_sales = np.load('./datasets/monthly_sales.npy')\n",
    "rgb_array = np.load('./datasets/rgb_array.npy')\n",
    "sudoku_game = np.load('./datasets/sudoku_game.npy')\n",
    "sudoku_solution = np.load('./datasets/sudoku_solution.npy')\n",
    "tree_census = np.load('./datasets/tree_census.npy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Understanding NumPy Arrays\n",
    "\n",
    "> Meet the incredible NumPy array! Learn how to create and change array shapes to suit your needs. Finally, discover NumPy's many data types and how they contribute to speedy array operations.\n",
    "\n",
    "\n",
    "### Introducing arrays\n",
    "\n",
    "![](../../images/numpy_intro.png)\n",
    "\n",
    "![](./images/np_intro.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your first NumPy array\n",
    "### Creating arrays from scratch\n",
    "### A range array\n",
    "### Array dimensionality\n",
    "### 3D array creation\n",
    "### The fourth dimension\n",
    "### Flattening and reshaping\n",
    "### NumPy data types\n",
    "### The dtype argument\n",
    "### Anticipating data types\n",
    "### A smaller sudoku game\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting and Updating Data\n",
    "\n",
    "> Sharpen your NumPy data wrangling skills by slicing, filtering, and sorting New York City’s tree census data. Create new arrays by pulling data based on conditional statements, and add and remove data along any dimension to suit your purpose. Along the way, you’ll learn the shape and dimension compatibility principles to prepare for super-fast array math.\n",
    "\n",
    "\n",
    "### Indexing and slicing arrays\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing and indexing trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stepping into 2D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering with masks\n",
    "In the last lesson, you sorted trees from smallest to largest. Now, you'll use fancy indexing to return the row of data representing the largest tree in tree_census. You'll also examine other trees located on the same block as the largest tree: are they also large?\n",
    "\n",
    "numpy is loaded as np, and the tree_census array is available. As a reminder, the tree_census columns in order refer to a tree's ID, its block ID, its trunk diameter, and its stump diameter.\n",
    "\n",
    "Instructions:\n",
    "- Using Boolean indexing, create an array, largest_tree_data, which contains the row of data on the largest tree in tree_census corresponding to the tree with a diameter of 51.\n",
    "- Slice largest_tree_data to retrieve only the block id of the block the largest tree is located on; save this block id as largest_tree_block_id.\n",
    "- Using fancy indexing, create an array called trees_on_largest_tree_block which contains data on all trees with the same block ID as the largest tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    61 501882     51      0]]\n",
      "[501882]\n",
      "[[    60 501882      8      0]\n",
      " [    61 501882     51      0]\n",
      " [    62 501882      7      0]\n",
      " [    63 501882      4      0]\n",
      " [    64 501882     15      0]\n",
      " [    65 501882      3      0]\n",
      " [    66 501882      8      0]\n",
      " [    67 501882      6      0]\n",
      " [    68 501882      6      0]\n",
      " [    69 501882      3      0]]\n"
     ]
    }
   ],
   "source": [
    "# Create an array which contains row data on the largest tree in tree_census\n",
    "largest_tree_data = tree_census[tree_census[:, 2] == 51]\n",
    "print(largest_tree_data)\n",
    "\n",
    "# Slice largest_tree_data to get only the block ID\n",
    "largest_tree_block_id = largest_tree_data[:, 1]\n",
    "print(largest_tree_block_id)\n",
    "\n",
    "# Create an array which contains row data on all trees with largest_tree_block_id\n",
    "trees_on_largest_tree_block = tree_census[tree_census[:, 1] == largest_tree_block_id]\n",
    "print(trees_on_largest_tree_block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your work, it looks like the largest tree on the tree_census is the only really big tree on its block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fancy indexing vs. np.where()\n",
    "\n",
    "ou and your tree research team are double-checking collection data by visiting a few trees in person to confirm their measurements. You've been assigned to check the data for trees on block 313879, and you'd like to make a small array of just the tree data that relates to your work.\n",
    "\n",
    "numpy is loaded as np, and the tree_census array is available. As a reminder, the tree_census columns in order refer to a tree's ID, its block ID, its trunk diameter, and its stump diameter.\n",
    "\n",
    "Instructions:\n",
    "- Using fancy indexing, create an array called block_313879 which only contains data for trees with a block ID of 313879.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1115 313879      3      0]\n",
      " [  1116 313879     17      0]]\n"
     ]
    }
   ],
   "source": [
    "# Create the block_313879 array containing trees on block 313879\n",
    "block_313879 = tree_census[tree_census[:, 1] ==  313879]\n",
    "print(block_313879)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using np.where(), create an array of row_indices for trees with a block ID of 313879.\n",
    "- Using row_indices, create block_313879, which contains data for trees on block 313879."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1115 313879      3      0]\n",
      " [  1116 313879     17      0]]\n"
     ]
    }
   ],
   "source": [
    "# Create an array of row_indices for trees on block 313879\n",
    "row_indices = np.where(tree_census[:,1] == 313879)\n",
    "\n",
    "# Create an array which only contains data for trees on block 313879\n",
    "block_313879 = tree_census[row_indices]\n",
    "print(block_313879)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great filtering. You probably noticed that fancy indexing is more elegant than np.where() in this example. That's because we haven't really tapped into the power of np.where() yet. It's most useful for finding indices and then using that location information to update an array. We'll see an example of this in the next exercise, and also in the next lesson, where one of the functions takes indices as arguments!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Creating arrays from conditions\n",
    "\n",
    "Currently, the stump diameter and trunk diameter values in tree_census are in two different columns. Living trees have a stump diameter of zero while stumps have a trunk diameter of zero. If you'd like to include both living trees and stumps in certain research calculations, it might be useful to have their diameters together in just one column.\n",
    "\n",
    "numpy is loaded as np, and the tree_census array is available. As a reminder, the tree census columns in order refer to a tree's ID, its block ID, its trunk diameter, and its stump diameter.\n",
    "\n",
    "Instructions:\n",
    "- Create and print a 1D array called trunk_stump_diameters, which replaces a tree's trunk diameter with its stump diameter if the trunk diameter is zero.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24 20  3  3  4  4  4  4  4  3  3  4  2  2  3  4  4  4  3 14  3  4  7  8\n",
      "  7  8  7  5  6  5  5 17 31 19 21 18  4  5  3  4  3  4 13 13 13  5  4  4\n",
      "  4 11  5  4  5  8 51  7  4 15  3  8  6  6  3  4  3  2  3  3  6  5  5  5\n",
      "  5  9  4  4  7  7  6  5  4  4  5  5  5  7  3  5  3  3  6  6  8  7  4  5\n",
      "  4  4  4  4  6  5  3  4 12 12 12  5  6  6  6  6  6  5  5  6  7  7 25  5\n",
      "  5  4  6  6  7 11  6 17 13 14 14 20 15 13  7  7 10 17 14  4  6  7  8  7\n",
      "  7  6  7  5  2  2  2  2 26 25  2 15  6 20  5  9 15 13 15  3  2 13  6 12\n",
      " 15 18 22 18 18 15 17  7  3  7  8  4 12 11 12  3  9 12 11 10  8  6  6  7\n",
      "  7  3 15 12 12  4  5  5  5  4  4  5  4  9  2  4  4  6  5  5  2  5  5  4\n",
      "  4  5  5  6 11  4  5  7  3 14 11 10  7 15 10  5  6 10 10  6  5  4  4  3\n",
      "  5  4 14 12 11  8 14 12  9 12 11  7  8 10 10 12 11 12  5  5  6  9  9  8\n",
      "  5  5  5  6  6 12 12 11 12  8  9  5  5  5  8  2  2  2 14 18 14 14 22 15\n",
      " 19 14 18  7  7  7  8  8  5 10 14  2  2  2  2 11 12 12  3  3  3  3  3  6\n",
      "  6  8  2  2 11 11 11  9 11 12 13  9 11  6  4  5  5  2  2  8 10  7  9 11\n",
      " 11  1  2 26  4 13  2  4  3  4  4  4  4  3  4  2  2 12 13  5  4  2  3  3\n",
      " 25 11 11 14 22  2  3 10  2  2 13 19 26 21 19 14 14  5 19 15 11 15  6 19\n",
      " 17 12 13 15 12  2 16  2  2  2 25  2 21  2 15 16 14 13 11  8 11 13 12  7\n",
      " 24 19  3  3  4  6 11 17 19 19 17 15 13 15 27 16 15 20 17 16  4 10  9 14\n",
      " 11 12  8  9  9 13 14  7 11 14  3  7 16 17 13 14 16 12  4  5  3 16 11  9\n",
      "  9 10  8 10 11 11  8 11 11 11  9 11 10  9  5 12 11 13  9 15 16 12  7 10\n",
      "  6  9  5  9  6  6  3  3  5  4  4  4  4  6  4  7  6  7  6  5  7  8 20  9\n",
      " 11 11 10  9 11 12 10 18  7  4  4  4  4  3 19 12  3  4  5  4  4 17 15  8\n",
      "  4  5  6 25  6 11  3  3 15  4 14 12 15  2  3  2 11 11 14 12 15 12  8  9\n",
      "  9  8  7 12 15  4 11 10  6  7  9 38  6  3 15 11  5  4  2 13 21 26  4 18\n",
      " 10 17 20 19 21 19 18 18 17 24 27 22 21  9 17 17 19 28 21 11 23 28  7 33\n",
      " 30  5 26 27 22  2  2  2  3  4  3  3 12 17 15  2  3  3  6  6  6  6 18 13\n",
      " 25 25 22 25 21 19  3  3  3  4  4 19  4  4 24 27 20  3 19  5 12 26 13  7\n",
      " 13  4 20  5 14 20 11  3  4 19  4 17 22 24 15  7  5  4  5  5  4  4  4  8\n",
      "  4  4  7  6 10  8 11  2  9  8  4  3  3  2  2 22 22 24 23 20 21  5  6  7\n",
      "  4  2 15 19 20  4  4  7  2 17 10  3 11  2 10 11  4  4  3 13  3  3  3  3\n",
      "  4  3  3  3 14  3  9  9  9 10 20 14 19 16 22 22 17 18  9  9  7  9  3 14\n",
      " 13 15 16 18 21  3  8  3  9  8 11  9 10  5  5 11 16  3  4  3  4  5  4 10\n",
      " 10 12  9  9 13 11 10  3  3  3  4  3  4  4 10 25  5  5  1 34  1  1  1 15\n",
      " 11 11 13  7  7 12 13  3 17 14 18 15 17 14 13 20  9 11  4  9 13  9 19 20\n",
      "  8  8 20 19 13 44 17 25 14 12 14 15  6  6  7  5  5  5  5  3  9  9 17 13\n",
      "  3 13 20 20 18 18 21 20 19 22 18 21 25 21 21 18 20 18 23 23 23 18 24 22\n",
      "  2  7  2 11 19 21 14 20 13  2 18  2  2 31 25 31 25 11 22  2 18 17 18 21\n",
      " 22 16 16 18 15 23  5  6 13 19  7 16 16 20 15 18  1 15 10 24 18  2  3  2\n",
      " 17 12 14 17 23 18 12 13 23  3 17  8  8  8  4  9 22  2 14 23 20 23  3  7\n",
      "  3  6  4 12  4  4  2  6  4  3 17 19  4 19 15 14 17 20  2 16  3 12 10 11\n",
      "  4 11  4 30  8  4 39  3  7 11 18 22 19 21  7 21  2 16 11 20 21 22  8 16\n",
      "  2 23 14 14 13 20 21 15 19 28 17 16 12 11 11  6]\n"
     ]
    }
   ],
   "source": [
    "# Create and print a 1D array of tree and stump diameters\n",
    "trunk_stump_diameters = np.where(tree_census[:,2] == 0,tree_census[:,3], tree_census[:,2] )\n",
    "print(trunk_stump_diameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this is just a 1D array without any tree or block ID information. How do we add this information back to the tree_census array? That's the subject of our next lesson!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Adding and removing data\n",
    "\n",
    "![](./images/numpy_concat.png)\n",
    "\n",
    "#### Concatenating Rows\n",
    "- np.concatenate() concatenates along the first axis by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, 22],\n",
       "       [ 2, 21],\n",
       "       [ 3, 27],\n",
       "       [ 4, 26],\n",
       "       [ 5, 30],\n",
       "       [ 5, 17]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classroom_ids_and_sizes = np.array([[1, 22], [2, 21], [3, 27], [4, 26]])\n",
    "new_classrooms = np.array([[5, 30], [5, 17]])\n",
    "np.concatenate((classroom_ids_and_sizes, new_classrooms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating columns\n",
    "- Specify the ```axis = 1```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', '22', '1', 'James'],\n",
       "       ['2', '21', '1', 'George'],\n",
       "       ['3', '27', '3', 'Amy'],\n",
       "       ['4', '26', '3', 'Meehir']], dtype='<U11')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classroom_ids_and_sizes = np.array([[1, 22], [2, 21], [3, 27], [4, 26]])\n",
    "grade_levels_and_teachers = np.array([[1, \"James\"], [1, \"George\"], [3,\"Amy\"],[3, \"Meehir\"]])\n",
    "classroom_data = np.concatenate((classroom_ids_and_sizes, grade_levels_and_teachers), axis=1)\n",
    "classroom_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/np_shape.png)\n",
    "\n",
    "![](./images/np_dimension.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating compatibility\n",
    "array_1D = np.array([1, 2, 3])\n",
    "column_array_2D = array_1D.reshape((3, 1))\n",
    "display(column_array_2D)\n",
    "\n",
    "row_array_2D = array_1D.reshape((1, 3))\n",
    "display(row_array_2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/np_dimension2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', '22', '1', 'James'],\n",
       "       ['2', '21', '1', 'George'],\n",
       "       ['3', '27', '3', 'Amy'],\n",
       "       ['4', '26', '3', 'Meehir']], dtype='<U11')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classroom_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleting with np.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', '22', '1', 'James'],\n",
       "       ['3', '27', '3', 'Amy'],\n",
       "       ['4', '26', '3', 'Meehir']], dtype='<U11')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.delete(classroom_data, 1, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleting columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', '1', 'James'],\n",
       "       ['2', '1', 'George'],\n",
       "       ['3', '3', 'Amy'],\n",
       "       ['4', '3', 'Meehir']], dtype='<U11')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.delete(classroom_data, 1, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleting without an axis\n",
    "- Numpy will delete at the index of the flatten version of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', '22', '1', 'James'],\n",
       "       ['2', '21', '1', 'George'],\n",
       "       ['3', '27', '3', 'Amy'],\n",
       "       ['4', '26', '3', 'Meehir']], dtype='<U11')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classroom_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '1', 'James', '2', '21', '1', 'George', '3', '27', '3', 'Amy',\n",
       "       '4', '26', '3', 'Meehir'], dtype='<U11')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.delete(classroom_data, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding rows\n",
    "\n",
    "The research team has discovered two trees that were left off the tree_census. Your task is to add rows containing the data for these new trees to the end of the tree_census array. The new trees' data is saved in a 2D array called new_trees:\n",
    "\n",
    "numpy is loaded as np, and the tree_census and new_trees arrays are available.\n",
    "\n",
    "Instructions:\n",
    "- Add rows to the end of tree_census containing data for the new trees from the new_trees 2D array; save the new array as updated_tree_census.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_trees = np.array([[1211, 227386, 20, 0], [1212, 227386, 8, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4) (2, 4)\n",
      "[[     3 501451     24      0]\n",
      " [     4 501451     20      0]\n",
      " [     7 501911      3      0]\n",
      " ...\n",
      " [  1210 227386      6      0]\n",
      " [  1211 227386     20      0]\n",
      " [  1212 227386      8      0]]\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of tree_census and new_trees\n",
    "print(tree_census.shape, new_trees.shape)\n",
    "\n",
    "# Add rows to tree_census which contain data for the new trees\n",
    "updated_tree_census = np.concatenate((tree_census, new_trees))\n",
    "print(updated_tree_census)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding columns\n",
    "\n",
    "You finished the last set of exercises by creating an array called trunk_stump_diameters, which combined data from the trunk diameter and stump diameter columns into a 1D array. Now, you'll add that 1D array as a column to the tree_census array.\n",
    "\n",
    "numpy is loaded as np, and both the tree_census and trunk_stump_diameters arrays are available.\n",
    "\n",
    "Instructions:\n",
    "- Print the shapes of both tree_census and trunk_stump_diameters.\n",
    "- Reshape trunk_stump_diameters so that it can be appended as the last column in tree_census; call the reshaped array reshaped_diameters.\n",
    "- Concatenate reshaped_diameters to the end of tree_census so that it becomes the last column; call the new array concatenated_tree_census."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,) (1000, 4)\n",
      "[[     3 501451     24      0     24]\n",
      " [     4 501451     20      0     20]\n",
      " [     7 501911      3      0      3]\n",
      " ...\n",
      " [  1198 227387     11      0     11]\n",
      " [  1199 227387     11      0     11]\n",
      " [  1210 227386      6      0      6]]\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of tree_census and trunk_stump_diameters\n",
    "print(trunk_stump_diameters.shape, tree_census.shape)\n",
    "\n",
    "# Reshape trunk_stump_diameters\n",
    "reshaped_diameters = trunk_stump_diameters.reshape((1000, 1))\n",
    "\n",
    "# Concatenate reshaped_diameters to tree_census as the last column\n",
    "concatenated_tree_census = np.concatenate((tree_census, reshaped_diameters), axis = 1)\n",
    "print(concatenated_tree_census)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's right! Adding a 1D array to an existing 2D array requires you to reshape the 1D array into a 2D array first. We'll dive into shape compatibility issues like this even further in the next chapter on array mathematics!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting with np.delete()\n",
    "\n",
    "What if your tree research focuses only on living trees on publicly-owned city blocks? It might be helpful to delete some unneeded data like the stump diameter column and some trees located on private blocks.\n",
    "\n",
    "You've learned that NumPy's np.delete() function takes three arguments: the original array, the index or indices to be deleted, and the axis to delete along. If you don't know the index or indices of the array you'd like to delete, recall that when it is only passed one argument,np.where() returns an array of indices where a condition is met!\n",
    "\n",
    "numpy is loaded as np, and the tree_census 2D array is available. The columns in order refer to a tree's ID, block number, trunk diameter, and stump diameter.\n",
    "\n",
    "Instructions:\n",
    "- Delete the stump diameter column from tree_census, and save the new 2D array as tree_census_no_stumps.\n",
    "- Using np.where(), find the indices of any trees on block 313879, a private block. Save the indices in an array called private_block_indices.\n",
    "- Using the indices you just found using np.where(), delete the rows for trees on block 313879 from tree_census_no_stumps, saving the new 2D array as tree_census_clean.\n",
    "- Print the shape of tree_census_clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(998, 3)\n"
     ]
    }
   ],
   "source": [
    "# Delete the stump diameter column from tree_census\n",
    "tree_census_no_stumps = np.delete(tree_census, 3, axis=1)\n",
    "\n",
    "# Save the indices of the trees on block 313879\n",
    "private_block_indices = np.where(tree_census[:,1] == 313879)\n",
    "\n",
    "# Delete the rows for trees on block 313879 from tree_census_no_stumps\n",
    "tree_census_clean = np.delete(tree_census_no_stumps, private_block_indices, axis=0)\n",
    "\n",
    "# Print the shape of tree_census_clean\n",
    "print(tree_census_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't stump you! Notice that the new shape reflects two fewer rows and one fewer column than tree_census started with because of your deletions: just as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array Mathematics!\n",
    "\n",
    "> Leverage NumPy’s speedy vectorized operations to gather summary insights on sales data for American liquor stores, restaurants, and department stores. Vectorize Python functions for use in your NumPy code. Finally, use broadcasting logic to perform mathematical operations between arrays of different sizes.\n",
    "\n",
    "\n",
    "### Summarizing data\n",
    "\n",
    "#### Aggregating methods\n",
    "\n",
    "- ```.sum()```\n",
    "- ```.min()```\n",
    "- ```.max()```\n",
    "- ```.mean()```\n",
    "- ```.cumsum()```\n",
    "\n",
    "![](./images/summarizing1.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales totals\n",
    "\n",
    "### Plotting averages\n",
    "\n",
    "### Cumulative sales\n",
    "\n",
    "### Vectorized operations\n",
    "\n",
    "### Tax calculations\n",
    "\n",
    "### Projecting sales\n",
    "### Vectorizing .upper()\n",
    "\n",
    "### Broadcasting\n",
    "\n",
    "### Broadcastable or not?\n",
    "\n",
    "### Broadcasting across columns\n",
    "### Broadcasting across rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array Transformations\n",
    "\n",
    "NumPy meets the art world in this final chapter as we use image data from a Monet masterpiece to explore how you can use to augment image data. You’ll use flipping and transposing functionality to quickly transform our masterpiece. Next, you’ll pull the Monet array apart, make changes, and reconstruct it using array stacking to see the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Saving and loading arrays\n",
    "\n",
    "### Loading .npy files\n",
    "\n",
    "### Getting help\n",
    "\n",
    "### Update and save\n",
    "\n",
    "### Array acrobatics\n",
    "\n",
    "### Augmenting Monet\n",
    "\n",
    "### Transposing your masterpiece\n",
    "\n",
    "### Stacking and splitting\n",
    "\n",
    "### 2D split and stack\n",
    "\n",
    "### Splitting RGB data\n",
    "\n",
    "### Stacking RGB data\n",
    "\n",
    "### Congratulations!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('my_conda_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f080ef3f7e154a5496448b61eb994fbc79c03fae547c033702ffc1b7b2a346b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
